"""
Black Desert Game - Real-time Platform Sales Ranking Scraper
ì‹¤ì œ ì›¹ì‚¬ì´íŠ¸ì—ì„œ ì „ì„¸ê³„ ê° í”Œë«í¼ë³„ íŒë§¤ëŸ‰ ìˆœìœ„ë¥¼ ìˆ˜ì§‘í•˜ëŠ” ì‹œìŠ¤í…œ
"""

import requests
from bs4 import BeautifulSoup
import json
from datetime import datetime
from typing import Dict, List, Optional
import time
import re

class GameSalesScraper:
    """ê²Œì„ íŒë§¤ëŸ‰ ìŠ¤í¬ë˜í•‘ ë° ì§‘ê³„ í´ë˜ìŠ¤"""
    
    def __init__(self, data_file: str = "sales_data.json"):
        self.data_file = data_file
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        }
        self.data = self.load_data()
    
    def load_data(self) -> Dict:
        """ì €ì¥ëœ ë°ì´í„° ë¡œë“œ"""
        try:
            with open(self.data_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        except FileNotFoundError:
            return {
                "game_name": "Black Desert",
                "platforms": {},
                "last_updated": None,
                "history": []
            }
    
    def save_data(self):
        """ë°ì´í„° ì €ì¥"""
        self.data["last_updated"] = datetime.now().isoformat()
        with open(self.data_file, 'w', encoding='utf-8') as f:
            json.dump(self.data, f, ensure_ascii=False, indent=2)
    
    def scrape_steam_bestsellers(self) -> List[Dict]:
        """Steam ë² ìŠ¤íŠ¸ì…€ëŸ¬ ì°¨íŠ¸ ìŠ¤í¬ë˜í•‘"""
        print("\nğŸ® Steam ë² ìŠ¤íŠ¸ì…€ëŸ¬ ì°¨íŠ¸ ìˆ˜ì§‘ ì¤‘...")
        url = "https://store.steampowered.com/charts/topselling/global"
        
        try:
            response = requests.get(url, headers=self.headers, timeout=10)
            soup = BeautifulSoup(response.content, 'html.parser')
            
            games = []
            # Steam ì°¨íŠ¸ êµ¬ì¡° ë¶„ì„
            chart_items = soup.find_all('div', class_='Chart_ChartTable')
            
            if chart_items:
                rows = chart_items[0].find_all('a', class_='weeklytopsellers_TableRow')
                
                for i, row in enumerate(rows[:20], 1):
                    try:
                        title_elem = row.find('div', class_='weeklytopsellers_GameName')
                        title = title_elem.text.strip() if title_elem else f"Game #{i}"
                        
                        games.append({
                            'rank': i,
                            'title': title,
                            'platform': 'Steam (PC)',
                            'url': row.get('href', '')
                        })
                    except Exception as e:
                        print(f"  âš ï¸  í•­ëª© íŒŒì‹± ì˜¤ë¥˜: {e}")
                        continue
            
            print(f"âœ“ Steam: {len(games)}ê°œ ê²Œì„ ìˆ˜ì§‘ ì™„ë£Œ")
            return games
            
        except Exception as e:
            print(f"âœ— Steam ìŠ¤í¬ë˜í•‘ ì‹¤íŒ¨: {e}")
            return []
    
    def scrape_playstation_store(self, region: str = "US") -> List[Dict]:
        """PlayStation Store ì¸ê¸° ì°¨íŠ¸ API í˜¸ì¶œ"""
        print(f"\nğŸ® PlayStation Store ({region}) ë°ì´í„° ìˆ˜ì§‘ ì¤‘...")
        
        # PlayStation Store GraphQL API
        url = "https://web.np.playstation.com/api/graphql/v1/op"
        
        # ì¸ê¸° ê²Œì„ ì¹´í…Œê³ ë¦¬ ì¿¼ë¦¬
        params = {
            "operationName": "categoryGridRetrieve",
            "variables": json.dumps({
                "id": "44d8bb20-653e-431e-8ad0-c0a365f68d2f",  # Popular ì¹´í…Œê³ ë¦¬
                "pageArgs": {"size": 20, "offset": 0},
                "sortBy": {"name": "popularityScore", "isAscending": False},
                "filterBy": [],
                "facetOptions": []
            }),
            "extensions": json.dumps({
                "persistedQuery": {
                    "version": 1,
                    "sha256Hash": "9845afc0dbaab4965f6563fffc703f588c8e76792000e8610843b8d3ee9c4c09"
                }
            })
        }
        
        try:
            response = requests.get(url, params=params, headers=self.headers, timeout=10)
            
            if response.status_code == 200:
                data = response.json()
                games = []
                
                # API ì‘ë‹µ êµ¬ì¡°ì— ë”°ë¼ ë°ì´í„° ì¶”ì¶œ
                if 'data' in data and 'categoryGridRetrieve' in data['data']:
                    products = data['data']['categoryGridRetrieve'].get('products', [])
                    
                    for i, product in enumerate(products[:20], 1):
                        games.append({
                            'rank': i,
                            'title': product.get('name', f'Game #{i}'),
                            'platform': 'PlayStation Store',
                            'id': product.get('id', '')
                        })
                
                print(f"âœ“ PlayStation Store: {len(games)}ê°œ ê²Œì„ ìˆ˜ì§‘ ì™„ë£Œ")
                return games
            else:
                print(f"âœ— PlayStation Store API ì˜¤ë¥˜: {response.status_code}")
                return []
                
        except Exception as e:
            print(f"âœ— PlayStation Store ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
            return []
    
    def scrape_vgchartz_preorders(self) -> List[Dict]:
        """VGChartz ì˜ˆì•½ íŒë§¤ ì°¨íŠ¸ ìŠ¤í¬ë˜í•‘"""
        print("\nğŸ® VGChartz ì˜ˆì•½ íŒë§¤ ì°¨íŠ¸ ìˆ˜ì§‘ ì¤‘...")
        url = "https://www.vgchartz.com/preorders/"
        
        try:
            response = requests.get(url, headers=self.headers, timeout=10)
            soup = BeautifulSoup(response.content, 'html.parser')
            
            games = []
            # VGChartz í…Œì´ë¸” êµ¬ì¡° ë¶„ì„
            table = soup.find('table')
            
            if table:
                rows = table.find_all('tr')[1:]  # í—¤ë” ì œì™¸
                
                for i, row in enumerate(rows[:20], 1):
                    cols = row.find_all('td')
                    if len(cols) >= 2:
                        title = cols[1].text.strip()
                        
                        games.append({
                            'rank': i,
                            'title': title,
                            'platform': 'Multi-Platform',
                            'source': 'VGChartz'
                        })
            
            print(f"âœ“ VGChartz: {len(games)}ê°œ ê²Œì„ ìˆ˜ì§‘ ì™„ë£Œ")
            return games
            
        except Exception as e:
            print(f"âœ— VGChartz ìŠ¤í¬ë˜í•‘ ì‹¤íŒ¨: {e}")
            return []
    
    def search_game_ranking(self, game_name: str = "Black Desert") -> Dict:
        """íŠ¹ì • ê²Œì„ì˜ í”Œë«í¼ë³„ ìˆœìœ„ ê²€ìƒ‰"""
        print(f"\nğŸ” '{game_name}' ê²Œì„ ìˆœìœ„ ê²€ìƒ‰ ì¤‘...\n")
        
        results = {
            'game_name': game_name,
            'timestamp': datetime.now().isoformat(),
            'platforms': {}
        }
        
        # Steam ê²€ìƒ‰
        steam_games = self.scrape_steam_bestsellers()
        for game in steam_games:
            if game_name.lower() in game['title'].lower():
                results['platforms']['Steam'] = {
                    'rank': game['rank'],
                    'found': True,
                    'details': game
                }
                break
        else:
            results['platforms']['Steam'] = {'found': False, 'rank': None}
        
        time.sleep(1)  # Rate limiting
        
        # PlayStation Store ê²€ìƒ‰
        ps_games = self.scrape_playstation_store()
        for game in ps_games:
            if game_name.lower() in game['title'].lower():
                results['platforms']['PlayStation'] = {
                    'rank': game['rank'],
                    'found': True,
                    'details': game
                }
                break
        else:
            results['platforms']['PlayStation'] = {'found': False, 'rank': None}
        
        # ê²°ê³¼ ì €ì¥
        self.data['platforms'] = results['platforms']
        self.data['history'].append(results)
        self.save_data()
        
        return results
    
    def get_all_platform_rankings(self) -> Dict:
        """ëª¨ë“  í”Œë«í¼ì˜ ë² ìŠ¤íŠ¸ì…€ëŸ¬ ì°¨íŠ¸ ìˆ˜ì§‘"""
        print("\n" + "="*70)
        print("ì „ì²´ í”Œë«í¼ ë² ìŠ¤íŠ¸ì…€ëŸ¬ ì°¨íŠ¸ ìˆ˜ì§‘ ì‹œì‘")
        print("="*70)
        
        all_data = {
            'timestamp': datetime.now().isoformat(),
            'platforms': {}
        }
        
        # Steam
        steam_data = self.scrape_steam_bestsellers()
        if steam_data:
            all_data['platforms']['Steam'] = steam_data
        
        time.sleep(2)  # Rate limiting
        
        # PlayStation Store
        ps_data = self.scrape_playstation_store()
        if ps_data:
            all_data['platforms']['PlayStation'] = ps_data
        
        time.sleep(2)  # Rate limiting
        
        # VGChartz
        vgc_data = self.scrape_vgchartz_preorders()
        if vgc_data:
            all_data['platforms']['VGChartz'] = vgc_data
        
        # ê²°ê³¼ ì €ì¥
        self.data['all_rankings'] = all_data
        self.save_data()
        
        return all_data
    
    def display_rankings(self, results: Dict):
        """ìˆœìœ„ ê²°ê³¼ í‘œì‹œ"""
        print("\n" + "="*70)
        print(f"ê²Œì„: {results.get('game_name', 'Unknown')}")
        print(f"ê²€ìƒ‰ ì‹œê°„: {results.get('timestamp', 'N/A')}")
        print("="*70)
        
        for platform, data in results.get('platforms', {}).items():
            print(f"\nğŸ“Š {platform}:")
            if data.get('found'):
                print(f"  âœ“ ìˆœìœ„: {data['rank']}ìœ„")
                if 'details' in data:
                    print(f"  ì œëª©: {data['details'].get('title', 'N/A')}")
            else:
                print(f"  âœ— Top 20 ì°¨íŠ¸ì— ì—†ìŒ")
        
        print("\n" + "="*70)
    
    def display_all_rankings(self, data: Dict):
        """ì „ì²´ í”Œë«í¼ ìˆœìœ„ í‘œì‹œ"""
        print("\n" + "="*70)
        print("ì „ì„¸ê³„ í”Œë«í¼ë³„ ë² ìŠ¤íŠ¸ì…€ëŸ¬ TOP 10")
        print(f"ìˆ˜ì§‘ ì‹œê°„: {data.get('timestamp', 'N/A')}")
        print("="*70)
        
        for platform, games in data.get('platforms', {}).items():
            print(f"\nğŸ® {platform}:")
            print("-" * 70)
            
            for game in games[:10]:
                rank = game.get('rank', '?')
                title = game.get('title', 'Unknown')
                print(f"  {rank:2d}ìœ„. {title}")
        
        print("\n" + "="*70)
        print(f"ì´ {len(data.get('platforms', {}))}ê°œ í”Œë«í¼ì—ì„œ ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ")
        print("="*70)
    
    def generate_report(self, filename: str = "rankings_report.txt"):
        """ë¦¬í¬íŠ¸ ìƒì„±"""
        with open(filename, 'w', encoding='utf-8') as f:
            f.write("ê²Œì„ íŒë§¤ëŸ‰ ìˆœìœ„ ë¦¬í¬íŠ¸\n")
            f.write("="*70 + "\n\n")
            
            if 'all_rankings' in self.data:
                data = self.data['all_rankings']
                f.write(f"ìˆ˜ì§‘ ì‹œê°„: {data.get('timestamp', 'N/A')}\n\n")
                
                for platform, games in data.get('platforms', {}).items():
                    f.write(f"\n{platform} ë² ìŠ¤íŠ¸ì…€ëŸ¬ TOP 20\n")
                    f.write("-"*70 + "\n")
                    
                    for game in games:
                        rank = game.get('rank', '?')
                        title = game.get('title', 'Unknown')
                        f.write(f"{rank:2d}ìœ„. {title}\n")
                    
                    f.write("\n")
            
            f.write(f"\nìƒì„± ì¼ì‹œ: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        
        print(f"\nâœ“ ë¦¬í¬íŠ¸ ìƒì„± ì™„ë£Œ: {filename}")


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    scraper = GameSalesScraper()
    
    print("\n" + "="*70)
    print("ê²Œì„ íŒë§¤ëŸ‰ ìˆœìœ„ ìŠ¤í¬ë˜í•‘ ì‹œìŠ¤í…œ")
    print("="*70)
    print("\nì˜µì…˜ì„ ì„ íƒí•˜ì„¸ìš”:")
    print("1. Black Desert ê²Œì„ ìˆœìœ„ ê²€ìƒ‰")
    print("2. ì „ì²´ í”Œë«í¼ ë² ìŠ¤íŠ¸ì…€ëŸ¬ TOP 20 ìˆ˜ì§‘")
    print("3. ì €ì¥ëœ ë°ì´í„° ë³´ê¸°")
    print("4. ë¦¬í¬íŠ¸ ìƒì„±")
    
    choice = input("\nì„ íƒ (1-4): ").strip()
    
    if choice == "1":
        game_name = input("ê²Œì„ ì´ë¦„ ì…ë ¥ (ê¸°ë³¸ê°’: Black Desert): ").strip()
        if not game_name:
            game_name = "Black Desert"
        
        results = scraper.search_game_ranking(game_name)
        scraper.display_rankings(results)
    
    elif choice == "2":
        all_data = scraper.get_all_platform_rankings()
        scraper.display_all_rankings(all_data)
    
    elif choice == "3":
        if 'all_rankings' in scraper.data:
            scraper.display_all_rankings(scraper.data['all_rankings'])
        else:
            print("\nì €ì¥ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    
    elif choice == "4":
        scraper.generate_report()
    
    else:
        print("\nì˜ëª»ëœ ì„ íƒì…ë‹ˆë‹¤.")


if __name__ == "__main__":
    main()
