#!/usr/bin/env python3
"""
ì¼ë³„ êµ­ê°€ë³„ S,D ìˆœìœ„ ê·¸ë˜í”„ ìƒì„± ìŠ¤í¬ë¦½íŠ¸
"""
import json
import copy  # âœ… FIX: deepcopyë¥¼ ìœ„í•´ ì¶”ê°€
import matplotlib.pyplot as plt
import matplotlib.dates as mdates
from datetime import datetime
import os
import requests
from pathlib import Path
import matplotlib.font_manager as fm
from io import BytesIO

# í•œê¸€ í°íŠ¸ ì„¤ì •
def setup_korean_font():
    """í•œê¸€ í°íŠ¸ ì„¤ì • (ì´ëª¨ì§€ ì§€ì› í¬í•¨)"""
    try:
        font_list = fm.findSystemFonts(fontpaths=None, fontext='ttf')
        korean_fonts = [
            'NanumGothic', 'NanumBarunGothic', 'NanumSquare',
            'Malgun Gothic', 'AppleGothic', 'Noto Sans KR', 'Noto Sans CJK KR'
        ]
        
        korean_font_found = False
        for font_path in font_list:
            for korean_font in korean_fonts:
                if korean_font.lower() in font_path.lower():
                    font_name = fm.FontProperties(fname=font_path).get_name()
                    korean_font_found = True
                    break
            if korean_font_found:
                break
        
        if korean_font_found:
            plt.rcParams['font.family'] = [font_name, 'DejaVu Sans', 'sans-serif']
            plt.rcParams['font.sans-serif'] = [font_name, 'Apple Color Emoji', 'Segoe UI Emoji', 'Noto Color Emoji', 'DejaVu Sans']
            plt.rcParams['axes.unicode_minus'] = False
            print(f'âœ“ Korean font set: {font_name} (with emoji support)')
        else:
            print('âš ï¸  Korean font not found, using default font with emoji support')
            plt.rcParams['font.family'] = ['DejaVu Sans', 'sans-serif']
            plt.rcParams['font.sans-serif'] = ['DejaVu Sans', 'Apple Color Emoji', 'Segoe UI Emoji', 'Noto Color Emoji']
            plt.rcParams['axes.unicode_minus'] = False
        
    except Exception as e:
        print(f'âš ï¸  Font setup error: {e}')
        plt.rcParams['font.family'] = 'DejaVu Sans'
        plt.rcParams['axes.unicode_minus'] = False

def load_data(filepath):
    """JSON ë°ì´í„° ë¡œë“œ"""
    with open(filepath, 'r', encoding='utf-8') as f:
        return json.load(f)

# =============================================================================
# ê³µí†µ ìƒìˆ˜ (crimson_trackerì˜ MARKET_WEIGHTSì™€ í†µì¼)
# =============================================================================

_US_BASE = 30.0
PS_MARKET_MULTIPLIER = {
    # Americas
    'ë¯¸êµ­': 30.0 / _US_BASE * 10,
    'ìºë‚˜ë‹¤': 4.5  / _US_BASE * 10,
    'ë¸Œë¼ì§ˆ': 2.5  / _US_BASE * 10,
    'ë©•ì‹œì½”': 2.0  / _US_BASE * 10,
    'ì•„ë¥´í—¨í‹°ë‚˜': 0.9 / _US_BASE * 10,
    'ì¹ ë ˆ':   0.8 / _US_BASE * 10,
    'ì½œë¡¬ë¹„ì•„': 0.7 / _US_BASE * 10,
    'í˜ë£¨':   0.4 / _US_BASE * 10,
    'ìš°ë£¨ê³¼ì´': 0.3 / _US_BASE * 10,
    'ë³¼ë¦¬ë¹„ì•„': 0.2 / _US_BASE * 10,
    'ê³¼í…Œë§ë¼': 0.2 / _US_BASE * 10,
    'ì˜¨ë‘ë¼ìŠ¤': 0.2 / _US_BASE * 10,
    # Europe & Middle East
    'ì˜êµ­':   8.5 / _US_BASE * 10,
    'ë…ì¼':   6.5 / _US_BASE * 10,
    'í”„ë‘ìŠ¤':  6.0 / _US_BASE * 10,
    'ìŠ¤í˜ì¸':  4.0 / _US_BASE * 10,
    'ì´íƒˆë¦¬ì•„': 3.5 / _US_BASE * 10,
    'ë„¤ëœë€ë“œ': 1.8 / _US_BASE * 10,
    'ì‚¬ìš°ë””ì•„ë¼ë¹„ì•„': 1.5 / _US_BASE * 10,
    'ì•„ëì—ë¯¸ë¦¬íŠ¸': 1.2 / _US_BASE * 10,
    'í´ë€ë“œ':  1.2 / _US_BASE * 10,
    'ìŠ¤ìœ„ìŠ¤':  1.0 / _US_BASE * 10,
    'ìŠ¤ì›¨ë´':  1.0 / _US_BASE * 10,
    'ë´ë§ˆí¬':  0.9 / _US_BASE * 10,
    'í¬ë¥´íˆ¬ê°ˆ': 0.8 / _US_BASE * 10,
    'í•€ë€ë“œ':  0.8 / _US_BASE * 10,
    'ë…¸ë¥´ì›¨ì´': 0.8 / _US_BASE * 10,
    'ë‚¨ì•„ê³µ':  0.8 / _US_BASE * 10,
    'ì²´ì½”':   0.7 / _US_BASE * 10,
    'ë£¨ë§ˆë‹ˆì•„': 0.6 / _US_BASE * 10,
    'ê·¸ë¦¬ìŠ¤':  0.5 / _US_BASE * 10,
    'í—ê°€ë¦¬':  0.5 / _US_BASE * 10,
    'ìš°í¬ë¼ì´ë‚˜': 0.5 / _US_BASE * 10,
    'ìŠ¬ë¡œë°”í‚¤ì•„': 0.3 / _US_BASE * 10,
    'ìŠ¬ë¡œë² ë‹ˆì•„': 0.3 / _US_BASE * 10,
    # Asia & Oceania
    'ì¼ë³¸':   8.0 / _US_BASE * 10,
    'í˜¸ì£¼':   3.0 / _US_BASE * 10,
    'í•œêµ­':   2.8 / _US_BASE * 10,
    'ì¸ë„':   2.0 / _US_BASE * 10,
    'ëŒ€ë§Œ':   1.0 / _US_BASE * 10,
    'ì‹±ê°€í¬ë¥´': 0.8 / _US_BASE * 10,
    'íƒœêµ­':   0.9 / _US_BASE * 10,
    'í™ì½©':   0.9 / _US_BASE * 10,
    'ì¸ë„ë„¤ì‹œì•„': 0.8 / _US_BASE * 10,
    'ë§ë ˆì´ì‹œì•„': 0.7 / _US_BASE * 10,
    'ë² íŠ¸ë‚¨':  0.7 / _US_BASE * 10,
    'í•„ë¦¬í•€':  0.6 / _US_BASE * 10,
    'ë‰´ì§ˆëœë“œ': 0.6 / _US_BASE * 10,
    'ì¤‘êµ­':   0.2 / _US_BASE * 10,
}
PS_MARKET_MULTIPLIER_DEFAULT = 0.10

import math as _math

_A1   = 600.0
_A20  = 70.0
_A100 = 15.0
_k1   = _math.log(_A1 / _A20)  / (20 - 1)
_k2   = _math.log(_A20 / _A100) / (100 - 20)

def rank_to_daily_sales(rank):
    """
    ìˆœìœ„ â†’ ì¼ì¼ íŒë§¤ëŸ‰(ê¸°ë³¸ ì‹œì¥ ê¸°ì¤€).
    1ìœ„=600, 20ìœ„=70, 100ìœ„=15 ì•µì»¤ ê¸°ë°˜ ë‘ êµ¬ê°„ ì§€ìˆ˜ ê³¡ì„ 
    """
    if rank is None or rank == '-':
        return 0.0
    r = int(rank)
    if r <= 20:
        return _A1 * _math.exp(-_k1 * (r - 1))
    else:
        return _A20 * _math.exp(-_k2 * (r - 20))

def get_multiplier(country: str) -> float:
    """êµ­ê°€ëª… â†’ PS ì‹œì¥ ë°°ìœ¨ ë°˜í™˜"""
    return PS_MARKET_MULTIPLIER.get(country, PS_MARKET_MULTIPLIER_DEFAULT)

def parse_data(data):
    """ë°ì´í„° íŒŒì‹± ë° êµ¬ì¡°í™”"""
    countries = set()
    dates = []
    
    for entry in data:
        countries.update(entry['raw_results'].keys())
        dates.append(datetime.fromisoformat(entry['timestamp']))
    
    countries = sorted(list(countries))
    
    country_data = {
        country: {
            'dates': [],
            'standard': [],
            'deluxe': []
        }
        for country in countries
    }
    
    for entry in data:
        date = datetime.fromisoformat(entry['timestamp'])
        for country in countries:
            if country in entry['raw_results']:
                country_data[country]['dates'].append(date)
                country_data[country]['standard'].append(entry['raw_results'][country]['standard'])
                country_data[country]['deluxe'].append(entry['raw_results'][country]['deluxe'])
    
    return country_data, sorted(dates)

def create_ranking_table(data, output_dir='output'):
    """ì—ë””ì…˜ë³„ ìˆœìœ„ë¥¼ í…ìŠ¤íŠ¸ í˜•ì‹ìœ¼ë¡œ ìƒì„± (Discordìš©)"""
    
    country_flags = {
        # ì•„ë©”ë¦¬ì¹´
        'ë¯¸êµ­': 'ğŸ‡ºğŸ‡¸', 'USA': 'ğŸ‡ºğŸ‡¸', 'United States': 'ğŸ‡ºğŸ‡¸', 'US': 'ğŸ‡ºğŸ‡¸',
        'ìºë‚˜ë‹¤': 'ğŸ‡¨ğŸ‡¦', 'Canada': 'ğŸ‡¨ğŸ‡¦',
        'ë¸Œë¼ì§ˆ': 'ğŸ‡§ğŸ‡·', 'Brazil': 'ğŸ‡§ğŸ‡·',
        'ë©•ì‹œì½”': 'ğŸ‡²ğŸ‡½', 'Mexico': 'ğŸ‡²ğŸ‡½',
        'ì•„ë¥´í—¨í‹°ë‚˜': 'ğŸ‡¦ğŸ‡·', 'Argentina': 'ğŸ‡¦ğŸ‡·',
        'ì¹ ë ˆ': 'ğŸ‡¨ğŸ‡±', 'Chile': 'ğŸ‡¨ğŸ‡±',
        'ì½œë¡¬ë¹„ì•„': 'ğŸ‡¨ğŸ‡´', 'Colombia': 'ğŸ‡¨ğŸ‡´',
        'í˜ë£¨': 'ğŸ‡µğŸ‡ª', 'Peru': 'ğŸ‡µğŸ‡ª',
        # ìœ ëŸ½ - ì„œìœ ëŸ½
        'ì˜êµ­': 'ğŸ‡¬ğŸ‡§', 'UK': 'ğŸ‡¬ğŸ‡§', 'United Kingdom': 'ğŸ‡¬ğŸ‡§', 'Britain': 'ğŸ‡¬ğŸ‡§',
        'ë…ì¼': 'ğŸ‡©ğŸ‡ª', 'Germany': 'ğŸ‡©ğŸ‡ª', 'Deutschland': 'ğŸ‡©ğŸ‡ª',
        'í”„ë‘ìŠ¤': 'ğŸ‡«ğŸ‡·', 'France': 'ğŸ‡«ğŸ‡·',
        'ìŠ¤í˜ì¸': 'ğŸ‡ªğŸ‡¸', 'Spain': 'ğŸ‡ªğŸ‡¸', 'EspaÃ±a': 'ğŸ‡ªğŸ‡¸',
        'ì´íƒˆë¦¬ì•„': 'ğŸ‡®ğŸ‡¹', 'Italy': 'ğŸ‡®ğŸ‡¹', 'Italia': 'ğŸ‡®ğŸ‡¹',
        'ë„¤ëœë€ë“œ': 'ğŸ‡³ğŸ‡±', 'Netherlands': 'ğŸ‡³ğŸ‡±',
        'ë²¨ê¸°ì—': 'ğŸ‡§ğŸ‡ª', 'Belgium': 'ğŸ‡§ğŸ‡ª',
        'ìŠ¤ìœ„ìŠ¤': 'ğŸ‡¨ğŸ‡­', 'Switzerland': 'ğŸ‡¨ğŸ‡­',
        'ì˜¤ìŠ¤íŠ¸ë¦¬ì•„': 'ğŸ‡¦ğŸ‡¹', 'Austria': 'ğŸ‡¦ğŸ‡¹',
        'ì•„ì¼ëœë“œ': 'ğŸ‡®ğŸ‡ª', 'Ireland': 'ğŸ‡®ğŸ‡ª',
        'í¬ë¥´íˆ¬ê°ˆ': 'ğŸ‡µğŸ‡¹', 'Portugal': 'ğŸ‡µğŸ‡¹',
        'ë£©ì…ˆë¶€ë¥´í¬': 'ğŸ‡±ğŸ‡º', 'Luxembourg': 'ğŸ‡±ğŸ‡º',
        # ìœ ëŸ½ - ë¶ìœ ëŸ½
        'ìŠ¤ì›¨ë´': 'ğŸ‡¸ğŸ‡ª', 'Sweden': 'ğŸ‡¸ğŸ‡ª',
        'ë…¸ë¥´ì›¨ì´': 'ğŸ‡³ğŸ‡´', 'Norway': 'ğŸ‡³ğŸ‡´',
        'ë´ë§ˆí¬': 'ğŸ‡©ğŸ‡°', 'Denmark': 'ğŸ‡©ğŸ‡°',
        'í•€ë€ë“œ': 'ğŸ‡«ğŸ‡®', 'Finland': 'ğŸ‡«ğŸ‡®',
        'ì•„ì´ìŠ¬ë€ë“œ': 'ğŸ‡®ğŸ‡¸', 'Iceland': 'ğŸ‡®ğŸ‡¸',
        # ìœ ëŸ½ - ë™ìœ ëŸ½
        'í´ë€ë“œ': 'ğŸ‡µğŸ‡±', 'Poland': 'ğŸ‡µğŸ‡±',
        'ì²´ì½”': 'ğŸ‡¨ğŸ‡¿', 'Czech Republic': 'ğŸ‡¨ğŸ‡¿', 'Czechia': 'ğŸ‡¨ğŸ‡¿',
        'í—ê°€ë¦¬': 'ğŸ‡­ğŸ‡º', 'Hungary': 'ğŸ‡­ğŸ‡º',
        'ìŠ¬ë¡œë°”í‚¤ì•„': 'ğŸ‡¸ğŸ‡°', 'Slovakia': 'ğŸ‡¸ğŸ‡°',
        'ë£¨ë§ˆë‹ˆì•„': 'ğŸ‡·ğŸ‡´', 'Romania': 'ğŸ‡·ğŸ‡´',
        'ë¶ˆê°€ë¦¬ì•„': 'ğŸ‡§ğŸ‡¬', 'Bulgaria': 'ğŸ‡§ğŸ‡¬',
        'í¬ë¡œì•„í‹°ì•„': 'ğŸ‡­ğŸ‡·', 'Croatia': 'ğŸ‡­ğŸ‡·',
        'ìŠ¬ë¡œë² ë‹ˆì•„': 'ğŸ‡¸ğŸ‡®', 'Slovenia': 'ğŸ‡¸ğŸ‡®',
        'ê·¸ë¦¬ìŠ¤': 'ğŸ‡¬ğŸ‡·', 'Greece': 'ğŸ‡¬ğŸ‡·',
        'ëŸ¬ì‹œì•„': 'ğŸ‡·ğŸ‡º', 'Russia': 'ğŸ‡·ğŸ‡º',
        'ìš°í¬ë¼ì´ë‚˜': 'ğŸ‡ºğŸ‡¦', 'Ukraine': 'ğŸ‡ºğŸ‡¦',
        # ìœ ëŸ½ - ë°œíŠ¸ 3êµ­
        'ì—ìŠ¤í† ë‹ˆì•„': 'ğŸ‡ªğŸ‡ª', 'Estonia': 'ğŸ‡ªğŸ‡ª',
        'ë¼íŠ¸ë¹„ì•„': 'ğŸ‡±ğŸ‡»', 'Latvia': 'ğŸ‡±ğŸ‡»',
        'ë¦¬íˆ¬ì•„ë‹ˆì•„': 'ğŸ‡±ğŸ‡¹', 'Lithuania': 'ğŸ‡±ğŸ‡¹',
        # ìœ ëŸ½ - ê¸°íƒ€
        'í„°í‚¤': 'ğŸ‡¹ğŸ‡·', 'Turkey': 'ğŸ‡¹ğŸ‡·', 'TÃ¼rkiye': 'ğŸ‡¹ğŸ‡·',
        'í‚¤í”„ë¡œìŠ¤': 'ğŸ‡¨ğŸ‡¾', 'Cyprus': 'ğŸ‡¨ğŸ‡¾',
        'ëª°íƒ€': 'ğŸ‡²ğŸ‡¹', 'Malta': 'ğŸ‡²ğŸ‡¹',
        # ì•„ì‹œì•„-íƒœí‰ì–‘
        'ì¼ë³¸': 'ğŸ‡¯ğŸ‡µ', 'Japan': 'ğŸ‡¯ğŸ‡µ',
        'í•œêµ­': 'ğŸ‡°ğŸ‡·', 'ëŒ€í•œë¯¼êµ­': 'ğŸ‡°ğŸ‡·', 'Korea': 'ğŸ‡°ğŸ‡·', 'South Korea': 'ğŸ‡°ğŸ‡·',
        'ì¤‘êµ­': 'ğŸ‡¨ğŸ‡³', 'China': 'ğŸ‡¨ğŸ‡³',
        'í™ì½©': 'ğŸ‡­ğŸ‡°', 'Hong Kong': 'ğŸ‡­ğŸ‡°',
        'ëŒ€ë§Œ': 'ğŸ‡¹ğŸ‡¼', 'Taiwan': 'ğŸ‡¹ğŸ‡¼',
        'í˜¸ì£¼': 'ğŸ‡¦ğŸ‡º', 'Australia': 'ğŸ‡¦ğŸ‡º',
        'ë‰´ì§ˆëœë“œ': 'ğŸ‡³ğŸ‡¿', 'New Zealand': 'ğŸ‡³ğŸ‡¿',
        'ì‹±ê°€í¬ë¥´': 'ğŸ‡¸ğŸ‡¬', 'Singapore': 'ğŸ‡¸ğŸ‡¬',
        'ë§ë ˆì´ì‹œì•„': 'ğŸ‡²ğŸ‡¾', 'Malaysia': 'ğŸ‡²ğŸ‡¾',
        'íƒœêµ­': 'ğŸ‡¹ğŸ‡­', 'Thailand': 'ğŸ‡¹ğŸ‡­',
        'ì¸ë„ë„¤ì‹œì•„': 'ğŸ‡®ğŸ‡©', 'Indonesia': 'ğŸ‡®ğŸ‡©',
        'ì¸ë„': 'ğŸ‡®ğŸ‡³', 'India': 'ğŸ‡®ğŸ‡³',
        # ì¤‘ë™
        'ì‚¬ìš°ë””ì•„ë¼ë¹„ì•„': 'ğŸ‡¸ğŸ‡¦', 'Saudi Arabia': 'ğŸ‡¸ğŸ‡¦',
        'ì•„ëì—ë¯¸ë¦¬íŠ¸': 'ğŸ‡¦ğŸ‡ª', 'UAE': 'ğŸ‡¦ğŸ‡ª', 'United Arab Emirates': 'ğŸ‡¦ğŸ‡ª',
        'ì¿ ì›¨ì´íŠ¸': 'ğŸ‡°ğŸ‡¼', 'Kuwait': 'ğŸ‡°ğŸ‡¼',
        'ì¹´íƒ€ë¥´': 'ğŸ‡¶ğŸ‡¦', 'Qatar': 'ğŸ‡¶ğŸ‡¦',
        'ë°”ë ˆì¸': 'ğŸ‡§ğŸ‡­', 'Bahrain': 'ğŸ‡§ğŸ‡­',
        'ì˜¤ë§Œ': 'ğŸ‡´ğŸ‡²', 'Oman': 'ğŸ‡´ğŸ‡²',
        'ì´ìŠ¤ë¼ì—˜': 'ğŸ‡®ğŸ‡±', 'Israel': 'ğŸ‡®ğŸ‡±',
        # ì•„í”„ë¦¬ì¹´
        'ë‚¨ì•„ê³µ': 'ğŸ‡¿ğŸ‡¦', 'South Africa': 'ğŸ‡¿ğŸ‡¦',
    }
    
    latest_entry = data[-1]
    raw_results = latest_entry['raw_results']
    
    # Standard Edition ìˆœìœ„ í…ìŠ¤íŠ¸ ìƒì„±
    rank_groups_std = {}
    for country, ranks in raw_results.items():
        std_rank = ranks['standard']
        if std_rank is not None:
            if std_rank not in rank_groups_std:
                rank_groups_std[std_rank] = []
            rank_groups_std[std_rank].append(country)
    
    for rank in rank_groups_std:
        rank_groups_std[rank] = sorted(
            rank_groups_std[rank],
            key=lambda c: get_multiplier(c),
            reverse=True
        )
    
    std_text = "**Standard Edition Rankings:**\n"
    for rank in sorted(rank_groups_std.keys()):
        countries = rank_groups_std[rank]
        countries_with_flags = [f"{country_flags.get(c, 'ğŸ³ï¸')} {c}" for c in countries]
        std_text += f"**#{rank}** {', '.join(countries_with_flags)}\n"
    
    # Deluxe Edition ìˆœìœ„ í…ìŠ¤íŠ¸ ìƒì„±
    rank_groups_dlx = {}
    for country, ranks in raw_results.items():
        dlx_rank = ranks['deluxe']
        if dlx_rank is not None:
            if dlx_rank not in rank_groups_dlx:
                rank_groups_dlx[dlx_rank] = []
            rank_groups_dlx[dlx_rank].append(country)
    
    for rank in rank_groups_dlx:
        rank_groups_dlx[rank] = sorted(
            rank_groups_dlx[rank],
            key=lambda c: get_multiplier(c),
            reverse=True
        )
    
    dlx_text = "**Deluxe Edition Rankings:**\n"
    for rank in sorted(rank_groups_dlx.keys()):
        countries = rank_groups_dlx[rank]
        countries_with_flags = [f"{country_flags.get(c, 'ğŸ³ï¸')} {c}" for c in countries]
        dlx_text += f"**#{rank}** {', '.join(countries_with_flags)}\n"
    
    print('âœ“ Generated ranking text for Discord')
    
    return {
        'standard': std_text,
        'deluxe': dlx_text
    }

def get_latest_rankings(data):
    """ìµœì‹  ìˆœìœ„ ë°ì´í„°ë¥¼ ë”•ì…”ë„ˆë¦¬ í˜•íƒœë¡œ ë°˜í™˜"""
    latest_entry = data[-1]
    timestamp = datetime.fromisoformat(latest_entry['timestamp'])
    
    countries_sorted = sorted(
        latest_entry['raw_results'].items(),
        key=lambda x: x[1]['standard'] if x[1]['standard'] is not None else 999
    )
    
    return {
        'timestamp': timestamp,
        'rankings': countries_sorted
    }

def calculate_current_sales(rankings):
    """í˜„ì¬ ìˆœìœ„ ê¸°ë°˜ìœ¼ë¡œ ì‹¤ì‹œê°„ íŒë§¤ëŸ‰ ì¶”ì‚°"""
    std_sales = 0.0
    dlx_sales = 0.0

    for country, ranks in rankings:
        multiplier = get_multiplier(country)

        if ranks['standard'] is not None:
            std_sales += rank_to_daily_sales(ranks['standard']) * multiplier

        if ranks['deluxe'] is not None:
            dlx_sales += rank_to_daily_sales(ranks['deluxe']) * multiplier

    return {
        'standard': round(std_sales, 2),
        'deluxe':   round(dlx_sales, 2),
        'total':    round(std_sales + dlx_sales, 2)
    }


def estimate_daily_sales(data, output_dir='output'):
    """ì¼ë³„ ì—ë””ì…˜ë³„ íŒë§¤ëŸ‰ ì¶”ì‚° (PS ì ìœ ìœ¨ ê¸°ë°˜ ê°€ì¤‘ì¹˜)"""
    import os as os_module

    # âœ… FIX: ì›ë³¸ dataë¥¼ ê±´ë“œë¦¬ì§€ ì•Šë„ë¡ deepcopy ì‚¬ìš©
    # ê¸°ì¡´ data.copy()ëŠ” ì–•ì€ ë³µì‚¬(shallow copy)ë¼ ë‚´ë¶€ ë”•ì…”ë„ˆë¦¬ê°€
    # ê°™ì€ ì°¸ì¡°ë¥¼ ê³µìœ  â†’ is_historical í”Œë˜ê·¸ ì¶”ê°€ ì‹œ ì›ë³¸ì´ ì˜¤ì—¼ë˜ì–´
    # rank_history.jsonì´ ë³€ê²½ëœ ê²ƒìœ¼ë¡œ ê°ì§€ â†’ git rebase ì—ëŸ¬ ë°œìƒ
    sales_data_raw = copy.deepcopy(data)

    historical_file = 'historical_ranking_data.json'
    sales_data = sales_data_raw

    if os_module.path.exists(historical_file):
        with open(historical_file, 'r', encoding='utf-8') as f:
            historical_data = json.load(f)
        
        print(f'ğŸ“œ Loaded {len(historical_data)} historical ranking points for sales estimation')
        
        std_ranks = []
        dlx_ranks = []
        
        for entry in data:
            for country, ranks in entry['raw_results'].items():
                if ranks['standard'] is not None:
                    std_ranks.append(ranks['standard'])
                if ranks['deluxe'] is not None:
                    dlx_ranks.append(ranks['deluxe'])
        
        avg_std = sum(std_ranks) / len(std_ranks) if std_ranks else 15
        avg_dlx = sum(dlx_ranks) / len(dlx_ranks) if dlx_ranks else 8
        rank_gap = avg_std - avg_dlx
        
        print(f'   Average rank gap (Std - Dlx): {rank_gap:.1f}')
        
        historical_entries = []
        
        if data:
            countries = list(data[0]['raw_results'].keys())
        else:
            countries = ['ë¯¸êµ­', 'ì¼ë³¸', 'ì˜êµ­', 'ë…ì¼', 'í”„ë‘ìŠ¤', 'í•œêµ­']
        
        for item in historical_data:
            date_str  = item['date']
            country_ranks = item.get('country_ranks', {})

            wa_num, wa_den = 0.0, 0.0
            for c, v in country_ranks.items():
                if v is not None:
                    m = get_multiplier(c)
                    wa_num += v * m
                    wa_den += m
            if wa_den > 0:
                weighted_avg_rank = wa_num / wa_den
            else:
                weighted_avg_rank = item.get('average_rank', 15)

            raw_results = {}
            for country in countries:
                if country in country_ranks and country_ranks[country] is not None:
                    base = country_ranks[country]
                else:
                    base = weighted_avg_rank
                std_r = max(1, int(base + rank_gap / 2))
                dlx_r = max(1, int(base - rank_gap / 2))
                raw_results[country] = {
                    'standard': std_r,
                    'deluxe':   dlx_r
                }

            historical_entries.append({
                'timestamp': f'{date_str}T08:00:00',
                'raw_results': raw_results,
                'is_historical': True  # âœ… FIX: ìƒˆë¡œ ë§Œë“œëŠ” ê°ì²´ì— ì§ì ‘ í”Œë˜ê·¸ ì„¤ì •
            })
        
        # âœ… FIX: deepcopyëœ sales_data_rawì—ë§Œ í”Œë˜ê·¸ ì¶”ê°€ (ì›ë³¸ dataëŠ” ì ˆëŒ€ ìˆ˜ì • ì•ˆ í•¨)
        for e in sales_data_raw:
            e['is_historical'] = False

        sales_data = historical_entries + sales_data_raw
        print(f'   Total data points for sales estimation: {len(sales_data)}')
    else:
        # historical íŒŒì¼ì´ ì—†ëŠ” ê²½ìš°ì—ë„ deepcopy ë³¸ì— í”Œë˜ê·¸ ì¶”ê°€
        for e in sales_data_raw:
            e['is_historical'] = False
        sales_data = sales_data_raw

    os.makedirs(output_dir, exist_ok=True)

    # ë‚ ì§œë³„ ê·¸ë£¹í™” â†’ êµ­ê°€ë³„ ìµœê³  ìˆœìœ„ â†’ íŒë§¤ëŸ‰ ê³„ì‚°
    daily_sales: list = []
    date_groups: dict = {}

    for entry in sales_data:
        timestamp = datetime.fromisoformat(entry['timestamp'])
        date_str  = timestamp.strftime('%Y-%m-%d')
        date_groups.setdefault(date_str, []).append({
            'timestamp':     timestamp,
            'raw_results':   entry['raw_results'],
            'is_historical': entry.get('is_historical', False)
        })

    for date_str in sorted(date_groups.keys()):
        entries = date_groups[date_str]
        representative_timestamp = entries[0]['timestamp']
        is_historical = all(e['is_historical'] for e in entries)

        all_countries: set = set()
        for e in entries:
            all_countries.update(e['raw_results'].keys())

        best_ranks: dict = {}
        for country in all_countries:
            best_std, best_dlx = None, None
            for e in entries:
                if country in e['raw_results']:
                    s = e['raw_results'][country]['standard']
                    d = e['raw_results'][country]['deluxe']
                    if s is not None and (best_std is None or s < best_std):
                        best_std = s
                    if d is not None and (best_dlx is None or d < best_dlx):
                        best_dlx = d
            best_ranks[country] = {'standard': best_std, 'deluxe': best_dlx}

        std_sales = 0.0
        dlx_sales = 0.0
        for country, ranks in best_ranks.items():
            m = get_multiplier(country)
            if ranks['standard'] is not None:
                std_sales += rank_to_daily_sales(ranks['standard']) * m
            if ranks['deluxe'] is not None:
                dlx_sales += rank_to_daily_sales(ranks['deluxe']) * m

        daily_sales.append({
            'date':          representative_timestamp,
            'date_str':      date_str,
            'standard':      round(std_sales, 2),
            'deluxe':        round(dlx_sales, 2),
            'total':         round(std_sales + dlx_sales, 2),
            'is_historical': is_historical
        })
    
    # í‘œ ë°ì´í„° ìƒì„±
    table_data = []
    for item in daily_sales:
        table_data.append([
            item['date_str'] + (' *' if item['is_historical'] else ''),
            f"{int(item['standard']):,}",
            f"{int(item['deluxe']):,}",
            f"{int(item['total']):,}"
        ])
    
    fig, ax = plt.subplots(figsize=(10, max(10, len(table_data) * 0.35)))
    ax.axis('tight')
    ax.axis('off')
    
    headers = ['Date (* = estimated)', 'Standard\n(Units)', 'Deluxe\n(Units)', 'Total\n(Units)']
    
    table = ax.table(
        cellText=table_data,
        colLabels=headers,
        cellLoc='center',
        loc='center',
        colWidths=[0.34, 0.22, 0.22, 0.22]
    )
    
    table.auto_set_font_size(False)
    table.set_fontsize(9)
    table.scale(1, 1.8)
    
    for i in range(4):
        cell = table[(0, i)]
        cell.set_facecolor('#2E5984')
        cell.set_text_props(weight='bold', color='white')
    
    for i, item in enumerate(daily_sales, start=1):
        for j in range(4):
            cell = table[(i, j)]
            if item['is_historical']:
                cell.set_facecolor('#FFF3CD' if i % 2 == 0 else '#FFEAA7')
                cell.set_text_props(color='#856404')
            else:
                cell.set_facecolor('#F0F0F0' if i % 2 == 0 else '#FFFFFF')
    
    criteria_text = (
        "Estimation Criteria:\n"
        "â€¢ Rank â†’ Base Sales (continuous 2-segment curve):\n"
        "  1st: 600 units/day\n"
        "  5th: 382 units/day\n"
        "  10th: 217 units/day\n"
        "  20th:  70 units/day  â† boundary (smooth)\n"
        "  50th:  39 units/day\n"
        " 100th:  15 units/day\n\n"
        "â€¢ Market size multiplier (crimson_tracker\n"
        "  MARKET_WEIGHTS, US=10 normalized):\n"
        "  US Ã—10, JP Ã—2.67, UK Ã—2.83\n"
        "  DE Ã—2.17, FR Ã—2.0, KR Ã—0.93\n"
        "  Others Ã—0.03~1.5\n\n"
        "â€¢ Total: 49 countries combined"
    )
    
    fig.text(0.02, 0.02, criteria_text,
             fontsize=7,
             verticalalignment='bottom',
             horizontalalignment='left',
             bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.3))
    
    plt.tight_layout(rect=[0, 0.15, 1, 1])
    sales_table_path = f'{output_dir}/daily_sales_estimate.png'
    plt.savefig(sales_table_path, dpi=150, bbox_inches='tight', facecolor='white')
    plt.close()
    
    print(f'âœ“ Generated: daily_sales_estimate.png')
    
    # íˆìŠ¤í† ë¦¬ / ì‹¤ì œ êµ¬ê°„ ë¶„ë¦¬
    hist_items = [item for item in daily_sales if     item['is_historical']]
    real_items = [item for item in daily_sales if not item['is_historical']]

    # ê²½ê³„ ì—°ê²°ìš©
    bridge_std, bridge_dlx, bridge_tot, bridge_dates = [], [], [], []
    if hist_items and real_items:
        bridge_items = [hist_items[-1], real_items[0]]
        bridge_dates = [it['date']     for it in bridge_items]
        bridge_std   = [it['standard'] for it in bridge_items]
        bridge_dlx   = [it['deluxe']   for it in bridge_items]
        bridge_tot   = [it['total']    for it in bridge_items]

    h_dates = [it['date']     for it in hist_items]
    h_std   = [it['standard'] for it in hist_items]
    h_dlx   = [it['deluxe']   for it in hist_items]
    h_tot   = [it['total']    for it in hist_items]

    r_dates = [it['date']     for it in real_items]
    r_std   = [it['standard'] for it in real_items]
    r_dlx   = [it['deluxe']   for it in real_items]
    r_tot   = [it['total']    for it in real_items]

    # ëˆ„ì  ê³„ì‚° (ì „ì²´ ìˆœì„œ ìœ ì§€)
    all_dates = [it['date'] for it in daily_sales]
    cumulative_std   = []
    cumulative_dlx   = []
    cumulative_total = []
    for i in range(len(daily_sales)):
        cumulative_std.append(sum(it['standard'] for it in daily_sales[:i+1]))
        cumulative_dlx.append(sum(it['deluxe']   for it in daily_sales[:i+1]))
        cumulative_total.append(sum(it['total']  for it in daily_sales[:i+1]))

    # âœ… FIX: ëˆ„ì  êµ¬ê°„ ë¶„ë¦¬ â€” len(hist_items) ì¸ë±ìŠ¤ ìŠ¬ë¼ì´ì‹± ëŒ€ì‹ 
    # daily_salesì˜ is_historical í”Œë˜ê·¸ ê¸°ì¤€ìœ¼ë¡œ ì§ì ‘ ë¶„ë¦¬
    # ê¸°ì¡´ ë°©ì‹ì€ hist_itemsê°€ daily_sales ì•ë¶€ë¶„ì— ì—°ì†ì ìœ¼ë¡œ ìœ„ì¹˜í•œë‹¤ê³ 
    # ê°€ì •í•˜ì§€ë§Œ, ë‚ ì§œ ê²¹ì¹¨ ë“±ìœ¼ë¡œ ìˆœì„œê°€ ë’¤ì„ì¼ ê²½ìš° ì¸ë±ìŠ¤ê°€ í‹€ì–´ì§
    h_cum_dates, h_cum_std, h_cum_dlx, h_cum_tot = [], [], [], []
    r_cum_dates, r_cum_std, r_cum_dlx, r_cum_tot = [], [], [], []

    for i, item in enumerate(daily_sales):
        if item['is_historical']:
            h_cum_dates.append(all_dates[i])
            h_cum_std.append(cumulative_std[i])
            h_cum_dlx.append(cumulative_dlx[i])
            h_cum_tot.append(cumulative_total[i])
        else:
            r_cum_dates.append(all_dates[i])
            r_cum_std.append(cumulative_std[i])
            r_cum_dlx.append(cumulative_dlx[i])
            r_cum_tot.append(cumulative_total[i])

    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(16, 12))

    # ìƒë‹¨: ì¼ë³„ ì—ë””ì…˜ë³„ íŒë§¤ëŸ‰
    if h_dates:
        ax1.plot(h_dates, h_std, 'o--', label='Standard â€“ Est. (historical avg)',
                 linewidth=1.5, markersize=4, color='#90CAF9', alpha=0.8)
        ax1.plot(h_dates, h_dlx, 's--', label='Deluxe â€“ Est. (historical avg)',
                 linewidth=1.5, markersize=4, color='#F48FB1', alpha=0.8)
        ax1.fill_between(h_dates, h_std, alpha=0.06, color='#2E86AB')
        ax1.fill_between(h_dates, h_dlx, alpha=0.06, color='#A23B72')

    if bridge_dates:
        ax1.plot(bridge_dates, bridge_std, '--', linewidth=1, color='#90CAF9', alpha=0.5)
        ax1.plot(bridge_dates, bridge_dlx, '--', linewidth=1, color='#F48FB1', alpha=0.5)

    if r_dates:
        ax1.plot(r_dates, r_std, 'o-', label='Standard â€“ Est. (per-country data)',
                 linewidth=2, markersize=5, color='#2E86AB')
        ax1.plot(r_dates, r_dlx, 's-', label='Deluxe â€“ Est. (per-country data)',
                 linewidth=2, markersize=5, color='#A23B72')

    if hist_items and real_items:
        boundary = real_items[0]['date']
        ax1.axvline(x=boundary, color='gray', linestyle=':', linewidth=1.5, alpha=0.7)
        ax1.text(boundary, ax1.get_ylim()[1] if ax1.get_ylim()[1] != 1.0 else 5000,
                 ' â† per-country\ndata starts',
                 fontsize=8, color='gray', va='top')

    ax1.set_ylabel('Estimated Daily Sales (Units)', fontsize=12)
    ax1.set_title('Daily Estimated Sales by Edition\n'
                  '(dashed = historical avg estimate  |  solid = per-country data)',
                  fontsize=13, fontweight='bold')
    ax1.grid(True, alpha=0.3)
    ax1.legend(fontsize=9, loc='upper right')
    ax1.xaxis.set_major_formatter(mdates.DateFormatter('%m-%d'))
    ax1.xaxis.set_major_locator(mdates.DayLocator(interval=3))
    plt.setp(ax1.xaxis.get_majorticklabels(), rotation=45)

    # í•˜ë‹¨: ëˆ„ì  íŒë§¤ëŸ‰
    if hist_items:
        ax2.axvspan(all_dates[0], all_dates[len(hist_items) - 1],
                    alpha=0.07, color='orange', label='Historical estimate period')

    if h_cum_dates:
        ax2.plot(h_cum_dates, h_cum_std, 'o--', linewidth=1.5, markersize=3,
                 color='#90CAF9', alpha=0.8)
        ax2.plot(h_cum_dates, h_cum_dlx, 's--', linewidth=1.5, markersize=3,
                 color='#F48FB1', alpha=0.8)
        ax2.plot(h_cum_dates, h_cum_tot, '^--', linewidth=1.5, markersize=3,
                 color='#A8D5A2', alpha=0.8)

    # ê²½ê³„ ì—°ê²° (ëˆ„ì )
    if hist_items and real_items and h_cum_dates and r_cum_dates:
        for cum_list, color in [
            (cumulative_std,   '#2E86AB'),
            (cumulative_dlx,   '#A23B72'),
            (cumulative_total, '#27AE60'),
        ]:
            ax2.plot(
                [h_cum_dates[-1], r_cum_dates[0]],
                [cum_list[len(hist_items) - 1], cum_list[len(hist_items)]],
                '--', linewidth=1, color=color, alpha=0.5
            )

    if r_cum_dates:
        ax2.plot(r_cum_dates, r_cum_std,  'o-',
                 label='Standard (Cumulative)', linewidth=2, markersize=4, color='#2E86AB')
        ax2.plot(r_cum_dates, r_cum_dlx,  's-',
                 label='Deluxe (Cumulative)',   linewidth=2, markersize=4, color='#A23B72')
        ax2.plot(r_cum_dates, r_cum_tot,  '^-',
                 label='Total (Cumulative)',     linewidth=2, markersize=4, color='#27AE60')

    # ìµœì¢… ëˆ„ì  ê°’ í‘œì‹œ
    if cumulative_std:
        for cum, label_txt, color in [
            (cumulative_std,   f"{int(cumulative_std[-1]):,}",   '#2E86AB'),
            (cumulative_dlx,   f"{int(cumulative_dlx[-1]):,}",   '#A23B72'),
            (cumulative_total, f"{int(cumulative_total[-1]):,}", '#27AE60'),
        ]:
            ax2.annotate(label_txt,
                         xy=(all_dates[-1], cum[-1]),
                         xytext=(8, 0), textcoords='offset points',
                         fontsize=9, fontweight='bold', color=color)

    ax2.set_xlabel('Date', fontsize=12)
    ax2.set_ylabel('Cumulative Sales (Units)', fontsize=12)
    ax2.set_title('Cumulative Estimated Sales\n'
                  '(shaded area = historical estimate  |  solid = per-country data)',
                  fontsize=13, fontweight='bold')
    ax2.grid(True, alpha=0.3)
    ax2.legend(fontsize=9, loc='upper left')
    ax2.xaxis.set_major_formatter(mdates.DateFormatter('%m-%d'))
    ax2.xaxis.set_major_locator(mdates.DayLocator(interval=3))
    plt.setp(ax2.xaxis.get_majorticklabels(), rotation=45)
    
    criteria_text = (
        "Estimation Criteria:\n"
        "Rank â†’ Base Sales (continuous 2-segment curve): "
        "1st=600/day, 5th=382/day, 10th=217/day, 20th=70/day (boundary), 50th=39/day, 100th=15/day\n"
        "Market Multiplier (crimson_tracker MARKET_WEIGHTS, US=10): "
        "US Ã—10, JP Ã—2.67, UK Ã—2.83, DE Ã—2.17, FR Ã—2.0, KR Ã—0.93, Others Ã—0.03~1.5\n"
        "Total: 49 countries combined (PlayStation Store pre-order rankings)"
    )
    
    fig.text(0.5, 0.01, criteria_text,
             fontsize=8,
             verticalalignment='bottom',
             horizontalalignment='center',
             bbox=dict(boxstyle='round', facecolor='lightgray', alpha=0.3))
    
    plt.tight_layout(rect=[0, 0.05, 1, 1])
    sales_chart_path = f'{output_dir}/daily_sales_chart.png'
    plt.savefig(sales_chart_path, dpi=150, bbox_inches='tight')
    plt.close()
    
    print(f'âœ“ Generated: daily_sales_chart.png')
    
    return sales_table_path, sales_chart_path, daily_sales

def plot_country_rankings(country_data, output_dir='output'):
    """ê° êµ­ê°€ë³„ S,D ìˆœìœ„ ê·¸ë˜í”„ ìƒì„±"""
    os.makedirs(output_dir, exist_ok=True)
    
    for country, data in country_data.items():
        if not data['dates']:
            continue
            
        fig, ax = plt.subplots(figsize=(14, 7))
        
        ax.plot(data['dates'], data['standard'], 'o-', label='Standard', linewidth=2, markersize=4)
        ax.plot(data['dates'], data['deluxe'], 's-', label='Deluxe', linewidth=2, markersize=4)
        
        ax.set_xlabel('Date', fontsize=12)
        ax.set_ylabel('Rank', fontsize=12)
        ax.set_title(f'{country} - Daily Ranking Trends', fontsize=14, fontweight='bold')
        ax.invert_yaxis()
        ax.grid(True, alpha=0.3)
        ax.legend(fontsize=10)
        
        ax.xaxis.set_major_formatter(mdates.DateFormatter('%m-%d'))
        ax.xaxis.set_major_locator(mdates.DayLocator(interval=1))
        plt.xticks(rotation=45)
        
        plt.tight_layout()
        
        safe_country = country.replace('/', '_').replace('\\', '_')
        plt.savefig(f'{output_dir}/{safe_country}_ranking.png', dpi=150, bbox_inches='tight')
        plt.close()
        
        print(f'âœ“ Generated: {safe_country}_ranking.png')

def plot_all_countries_standard(country_data, output_dir='output'):
    """ëª¨ë“  êµ­ê°€ì˜ Standard ìˆœìœ„ë¥¼ í•˜ë‚˜ì˜ ê·¸ë˜í”„ì—"""
    os.makedirs(output_dir, exist_ok=True)
    
    fig, ax = plt.subplots(figsize=(16, 10))
    
    for country, data in sorted(country_data.items()):
        if data['dates']:
            ax.plot(data['dates'], data['standard'], 'o-', label=country, linewidth=1.5, markersize=3, alpha=0.7)
            
            if data['standard'] and data['standard'][-1] is not None:
                last_date = data['dates'][-1]
                last_rank = data['standard'][-1]
                ax.annotate(f'{int(last_rank)}',
                           xy=(last_date, last_rank),
                           xytext=(5, 0), textcoords='offset points',
                           fontsize=7, fontweight='bold',
                           bbox=dict(boxstyle='round,pad=0.2', facecolor='lightblue', alpha=0.6, edgecolor='none'))
    
    ax.set_xlabel('Date', fontsize=12)
    ax.set_ylabel('Rank', fontsize=12)
    ax.set_title('All Countries - Standard Ranking Trends', fontsize=14, fontweight='bold')
    ax.invert_yaxis()
    ax.grid(True, alpha=0.3)
    ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=8)
    
    ax.xaxis.set_major_formatter(mdates.DateFormatter('%m-%d'))
    ax.xaxis.set_major_locator(mdates.DayLocator(interval=1))
    plt.xticks(rotation=45)
    
    plt.tight_layout()
    plt.savefig(f'{output_dir}/all_countries_standard.png', dpi=150, bbox_inches='tight')
    plt.close()
    
    print(f'âœ“ Generated: all_countries_standard.png')

def plot_all_countries_deluxe(country_data, output_dir='output'):
    """ëª¨ë“  êµ­ê°€ì˜ Deluxe ìˆœìœ„ë¥¼ í•˜ë‚˜ì˜ ê·¸ë˜í”„ì—"""
    os.makedirs(output_dir, exist_ok=True)
    
    fig, ax = plt.subplots(figsize=(16, 10))
    
    for country, data in sorted(country_data.items()):
        if data['dates']:
            ax.plot(data['dates'], data['deluxe'], 's-', label=country, linewidth=1.5, markersize=3, alpha=0.7)
            
            if data['deluxe'] and data['deluxe'][-1] is not None:
                last_date = data['dates'][-1]
                last_rank = data['deluxe'][-1]
                ax.annotate(f'{int(last_rank)}',
                           xy=(last_date, last_rank),
                           xytext=(5, 0), textcoords='offset points',
                           fontsize=7, fontweight='bold',
                           bbox=dict(boxstyle='round,pad=0.2', facecolor='yellow', alpha=0.6, edgecolor='none'))
    
    ax.set_xlabel('Date', fontsize=12)
    ax.set_ylabel('Rank', fontsize=12)
    ax.set_title('All Countries - Deluxe Ranking Trends', fontsize=14, fontweight='bold')
    ax.invert_yaxis()
    ax.grid(True, alpha=0.3)
    ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=8)
    
    ax.xaxis.set_major_formatter(mdates.DateFormatter('%m-%d'))
    ax.xaxis.set_major_locator(mdates.DayLocator(interval=1))
    plt.xticks(rotation=45)
    
    plt.tight_layout()
    plt.savefig(f'{output_dir}/all_countries_deluxe.png', dpi=150, bbox_inches='tight')
    plt.close()
    
    print(f'âœ“ Generated: all_countries_deluxe.png')

def plot_daily_averages(country_data, output_dir='output'):
    """ì¼ë³„ Standardì™€ Deluxe í‰ê·  ìˆœìœ„ ê·¸ë˜í”„"""
    os.makedirs(output_dir, exist_ok=True)
    
    date_averages = {}
    
    for country, data in country_data.items():
        for i, date in enumerate(data['dates']):
            date_str = date.strftime('%Y-%m-%d')
            if date_str not in date_averages:
                date_averages[date_str] = {
                    'date': date,
                    'standard': [],
                    'deluxe': []
                }
            if data['standard'][i] is not None:
                date_averages[date_str]['standard'].append(data['standard'][i])
            if data['deluxe'][i] is not None:
                date_averages[date_str]['deluxe'].append(data['deluxe'][i])
    
    dates = []
    standard_avgs = []
    deluxe_avgs = []
    
    for date_str in sorted(date_averages.keys()):
        std_list = date_averages[date_str]['standard']
        dlx_list = date_averages[date_str]['deluxe']
        
        if std_list and dlx_list:
            dates.append(date_averages[date_str]['date'])
            standard_avgs.append(sum(std_list) / len(std_list))
            deluxe_avgs.append(sum(dlx_list) / len(dlx_list))
    
    if not dates:
        print('âš ï¸  No data to plot for daily averages')
        return
    
    fig, ax = plt.subplots(figsize=(14, 7))
    
    ax.plot(dates, deluxe_avgs, 's-', label='Deluxe Average', linewidth=2, markersize=5, color='#A23B72')
    ax.plot(dates, standard_avgs, 'o-', label='Standard Average', linewidth=2, markersize=5, color='#2E86AB')
    
    for i, date in enumerate(dates):
        ax.annotate(f'{deluxe_avgs[i]:.1f}',
                   xy=(date, deluxe_avgs[i]),
                   xytext=(0, 8), textcoords='offset points',
                   fontsize=7, ha='center',
                   bbox=dict(boxstyle='round,pad=0.3', facecolor='yellow', alpha=0.6, edgecolor='none'))
        
        ax.annotate(f'{standard_avgs[i]:.1f}',
                   xy=(date, standard_avgs[i]),
                   xytext=(0, -12), textcoords='offset points',
                   fontsize=7, ha='center',
                   bbox=dict(boxstyle='round,pad=0.3', facecolor='lightblue', alpha=0.6, edgecolor='none'))
    
    std_min_rank = min(standard_avgs)
    std_max_rank = max(standard_avgs)
    std_min_idx = standard_avgs.index(std_min_rank)
    std_max_idx = standard_avgs.index(std_max_rank)
    ax.plot(dates[std_min_idx], std_min_rank, 'go', markersize=10, label=f'Std Best: {std_min_rank:.1f}', zorder=5)
    ax.plot(dates[std_max_idx], std_max_rank, 'ro', markersize=10, label=f'Std Worst: {std_max_rank:.1f}', zorder=5)
    
    dlx_min_rank = min(deluxe_avgs)
    dlx_max_rank = max(deluxe_avgs)
    dlx_min_idx = deluxe_avgs.index(dlx_min_rank)
    dlx_max_idx = deluxe_avgs.index(dlx_max_rank)
    ax.plot(dates[dlx_min_idx], dlx_min_rank, 'g^', markersize=10, label=f'Dlx Best: {dlx_min_rank:.1f}', zorder=5)
    ax.plot(dates[dlx_max_idx], dlx_max_rank, 'r^', markersize=10, label=f'Dlx Worst: {dlx_max_rank:.1f}', zorder=5)
    
    ax.set_xlabel('Date', fontsize=12)
    ax.set_ylabel('Average Rank', fontsize=12)
    ax.set_title('Daily Average Rankings - Standard vs Deluxe', fontsize=14, fontweight='bold')
    ax.invert_yaxis()
    ax.grid(True, alpha=0.3)
    ax.legend(fontsize=10, loc='best')
    
    ax.xaxis.set_major_formatter(mdates.DateFormatter('%m-%d'))
    ax.xaxis.set_major_locator(mdates.DayLocator(interval=1))
    plt.xticks(rotation=45)
    
    plt.tight_layout()
    plt.savefig(f'{output_dir}/daily_averages.png', dpi=150, bbox_inches='tight')
    plt.close()
    
    print(f'âœ“ Generated: daily_averages.png')

def plot_top_countries(country_data, countries_to_plot, output_dir='output'):
    """ì£¼ìš” êµ­ê°€ë“¤ì˜ Standardì™€ Deluxe ìˆœìœ„ ë¹„êµ"""
    os.makedirs(output_dir, exist_ok=True)
    
    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(14, 12))
    
    for country in countries_to_plot:
        if country in country_data and country_data[country]['dates']:
            data = country_data[country]
            ax1.plot(data['dates'], data['standard'], 'o-', label=country, linewidth=2, markersize=4)
            
            if data['standard'] and data['standard'][-1] is not None:
                last_date = data['dates'][-1]
                last_rank = data['standard'][-1]
                ax1.annotate(f'{int(last_rank)}',
                           xy=(last_date, last_rank),
                           xytext=(5, 0), textcoords='offset points',
                           fontsize=8, fontweight='bold')
    
    ax1.set_xlabel('Date', fontsize=12)
    ax1.set_ylabel('Rank', fontsize=12)
    ax1.set_title('Major Countries - Standard Ranking', fontsize=14, fontweight='bold')
    ax1.invert_yaxis()
    ax1.grid(True, alpha=0.3)
    ax1.legend(fontsize=10)
    ax1.xaxis.set_major_formatter(mdates.DateFormatter('%m-%d'))
    ax1.xaxis.set_major_locator(mdates.DayLocator(interval=1))
    plt.setp(ax1.xaxis.get_majorticklabels(), rotation=45)
    
    for country in countries_to_plot:
        if country in country_data and country_data[country]['dates']:
            data = country_data[country]
            ax2.plot(data['dates'], data['deluxe'], 's-', label=country, linewidth=2, markersize=4)
            
            if data['deluxe'] and data['deluxe'][-1] is not None:
                last_date = data['dates'][-1]
                last_rank = data['deluxe'][-1]
                ax2.annotate(f'{int(last_rank)}',
                           xy=(last_date, last_rank),
                           xytext=(5, 0), textcoords='offset points',
                           fontsize=8, fontweight='bold')
    
    ax2.set_xlabel('Date', fontsize=12)
    ax2.set_ylabel('Rank', fontsize=12)
    ax2.set_title('Major Countries - Deluxe Ranking', fontsize=14, fontweight='bold')
    ax2.invert_yaxis()
    ax2.grid(True, alpha=0.3)
    ax2.legend(fontsize=10)
    ax2.xaxis.set_major_formatter(mdates.DateFormatter('%m-%d'))
    ax2.xaxis.set_major_locator(mdates.DayLocator(interval=1))
    plt.setp(ax2.xaxis.get_majorticklabels(), rotation=45)
    
    plt.tight_layout()
    plt.savefig(f'{output_dir}/top_countries_rankings.png', dpi=150, bbox_inches='tight')
    plt.close()
    
    print(f'âœ“ Generated: top_countries_rankings.png')

def send_latest_rankings_to_discord(webhook_url, latest_rankings, table_texts, daily_sales):
    """ì˜¤ëŠ˜ ë‚ ì§œ ìµœì‹  ìˆœìœ„ë¥¼ ë””ìŠ¤ì½”ë“œë¡œ ì „ì†¡ (í…ìŠ¤íŠ¸ í˜•ì‹)"""
    if not webhook_url:
        print('âš ï¸  Discord webhook URL not provided, skipping latest rankings notification')
        return
    
    try:
        timestamp = latest_rankings['timestamp']
        rankings = latest_rankings['rankings']
        
        latest_sales = calculate_current_sales(rankings) if rankings else None
        
        embed = {
            "title": "ğŸ“Š Latest Rankings Update",
            "description": f"**{timestamp.strftime('%Y-%m-%d %H:%M:%S')}** ê¸°ì¤€ ìµœì‹  ìˆœìœ„",
            "color": 3066993,
            "fields": [
                {
                    "name": "ğŸ“ˆ Total Countries Tracked",
                    "value": str(len(rankings)),
                    "inline": False
                }
            ],
            "footer": {
                "text": "Ranking Bot | Auto-update"
            },
            "timestamp": datetime.utcnow().isoformat()
        }
        
        if latest_sales:
            sales_text = (
                f"**Standard**: {int(latest_sales['standard']):,} units\n"
                f"**Deluxe**: {int(latest_sales['deluxe']):,} units\n"
                f"**Total**: {int(latest_sales['total']):,} units\n"
                f"*(PS Market Share Weighted)*"
            )
            embed["fields"].insert(0, {
                "name": "ğŸ’° Estimated Sales (Current)",
                "value": sales_text,
                "inline": True
            })
        
        if table_texts:
            embed["fields"].append({
                "name": "ğŸ“‹ All Rankings (Standard)",
                "value": table_texts['standard'][:1024],
                "inline": False
            })
            embed["fields"].append({
                "name": "ğŸ“‹ All Rankings (Deluxe)",
                "value": table_texts['deluxe'][:1024],
                "inline": False
            })
        
        payload = {
            "username": "Ranking Bot",
            "embeds": [embed]
        }
        
        print(f'ğŸ“¤ Sending latest rankings to Discord...')
        
        response = requests.post(webhook_url, json=payload, timeout=10)
        
        if response.status_code in [200, 204]:
            print('âœ… Latest rankings sent to Discord successfully!')
        else:
            print(f'âš ï¸  Failed to send latest rankings: {response.status_code}')
            print(f'Response: {response.text}')
            
    except Exception as e:
        print(f'âŒ Error sending latest rankings to Discord: {e}')

def send_discord_notification(webhook_url, country_data, dates, output_dir='output'):
    """ë””ìŠ¤ì½”ë“œ ì›¹í›…ìœ¼ë¡œ ì•Œë¦¼ ì „ì†¡ (ê·¸ë˜í”„ ì´ë¯¸ì§€ í¬í•¨)"""
    if not webhook_url:
        print('âš ï¸  Discord webhook URL not provided, skipping notification')
        return
    
    print(f'ğŸ” Discord webhook URL: {webhook_url[:50]}...')
    
    try:
        num_countries = len(country_data)
        date_range = f"{dates[0].strftime('%Y-%m-%d')} to {dates[-1].strftime('%Y-%m-%d')}"
        
        target_countries = ['ì¼ë³¸', 'ë¯¸êµ­', 'ì˜êµ­', 'ë…ì¼', 'í”„ë‘ìŠ¤', 'í•œêµ­']
        countries_to_plot = []
        
        for target in target_countries:
            possible_names = [target]
            if target == 'í•œêµ­':
                possible_names.extend(['ëŒ€í•œë¯¼êµ­', 'Korea', 'South Korea'])
            elif target == 'ë¯¸êµ­':
                possible_names.extend(['USA', 'United States', 'US'])
            elif target == 'ì˜êµ­':
                possible_names.extend(['UK', 'United Kingdom', 'Britain'])
            elif target == 'ë…ì¼':
                possible_names.extend(['Germany', 'Deutschland'])
            elif target == 'í”„ë‘ìŠ¤':
                possible_names.extend(['France'])
            elif target == 'ì¼ë³¸':
                possible_names.extend(['Japan'])
            
            for name in possible_names:
                if name in country_data:
                    countries_to_plot.append(name)
                    break
        
        if countries_to_plot:
            plot_top_countries(country_data, countries_to_plot, output_dir)
        
        # ìµœê·¼ ìˆœìœ„ ë³€í™”ê°€ í° êµ­ê°€ ì°¾ê¸°
        top_changes = []
        for country, data in country_data.items():
            if len(data['standard']) >= 2:
                prev_std = data['standard'][-2]
                curr_std = data['standard'][-1]
                if prev_std is not None and curr_std is not None:
                    change = prev_std - curr_std  # ì–‘ìˆ˜ = ìˆœìœ„ ìƒìŠ¹
                    top_changes.append((country, change, curr_std))
        
        top_changes.sort(key=lambda x: abs(x[1]), reverse=True)
        top_changes = top_changes[:5]
        
        changes_text = ""
        for country, change, curr_rank in top_changes:
            arrow = "â¬†ï¸" if change > 0 else "â¬‡ï¸" if change < 0 else "â¡ï¸"
            changes_text += f"{arrow} **{country}**: {abs(int(change))} ranks ({'up' if change > 0 else 'down' if change < 0 else 'no change'}) â†’ #{int(curr_rank)}\n"
        
        embed = {
            "title": "ğŸ“ˆ Ranking Update - Charts",
            "description": f"**{date_range}** | {num_countries} countries tracked",
            "color": 5814783,
            "fields": [],
            "footer": {
                "text": "Ranking Bot | Auto-update"
            },
            "timestamp": datetime.utcnow().isoformat()
        }
        
        if changes_text:
            embed["fields"].append({
                "name": "ğŸ”„ Notable Changes (Standard)",
                "value": changes_text,
                "inline": False
            })
        
        files_to_send = {}
        image_files = [
            ('daily_sales_chart.png', 'sales_chart'),
            ('top_countries_rankings.png', 'top_countries'),
            ('all_countries_deluxe.png', 'deluxe_chart'),
            ('all_countries_standard.png', 'standard_chart'),
            ('daily_averages.png', 'averages_chart')
        ]
        
        for filename, file_key in image_files:
            filepath = os.path.join(output_dir, filename)
            if os.path.exists(filepath):
                files_to_send[file_key] = (filename, open(filepath, 'rb'), 'image/png')
        
        if files_to_send:
            embed["image"] = {"url": f"attachment://{image_files[0][0]}"}
        
        payload = {
            "username": "Ranking Bot",
            "embeds": [embed]
        }
        
        print(f'ğŸ“¤ Sending to Discord with {len(files_to_send)} images...')
        
        if files_to_send:
            response = requests.post(
                webhook_url,
                data={"payload_json": json.dumps(payload)},
                files=files_to_send,
                timeout=30
            )
            for file_tuple in files_to_send.values():
                file_tuple[1].close()
        else:
            response = requests.post(webhook_url, json=payload, timeout=10)
        
        print(f'ğŸ“¬ Response status: {response.status_code}')
        
        if response.status_code == 204 or response.status_code == 200:
            print('âœ… Discord notification sent successfully!')
        else:
            print(f'âš ï¸  Discord notification failed: {response.status_code}')
            print(f'Response: {response.text}')
            
    except requests.exceptions.Timeout:
        print(f'âŒ Discord notification timeout - check your network connection')
    except requests.exceptions.RequestException as e:
        print(f'âŒ Discord notification error: {e}')
    except Exception as e:
        print(f'âŒ Error sending Discord notification: {e}')

def build_historical_data_from_weekly(output_path='historical_ranking_data.json'):
    """
    ì´ë¯¸ì§€ì—ì„œ ìˆ˜ì§‘í•œ ì£¼ë‹¨ìœ„ êµ­ê°€ë³„ ìˆœìœ„ë¥¼ historical_ranking_data.json í˜•ì‹ìœ¼ë¡œ ë³€í™˜.
    """
    import math as _m
    from datetime import timedelta

    weekly_raw = [
        ("2025-09-22", {"ë¯¸êµ­":12,"ì¼ë³¸":17,"í™ì½©":14,"ì¸ë„":4, "ì˜êµ­":18,"ë…ì¼":12,"í”„ë‘ìŠ¤":9, "ë©•ì‹œì½”":17,"ìºë‚˜ë‹¤":15,"í•œêµ­":4, "í˜¸ì£¼":12,"ë¸Œë¼ì§ˆ":12,"ìŠ¤í˜ì¸":14}),
        ("2025-09-29", {"ë¯¸êµ­":11,"ì¼ë³¸":None,"í™ì½©":17,"ì¸ë„":6, "ì˜êµ­":22,"ë…ì¼":16,"í”„ë‘ìŠ¤":12,"ë©•ì‹œì½”":13,"ìºë‚˜ë‹¤":20,"í•œêµ­":4, "í˜¸ì£¼":21,"ë¸Œë¼ì§ˆ":11,"ìŠ¤í˜ì¸":11}),
        ("2025-10-06", {"ë¯¸êµ­":16,"ì¼ë³¸":15,"í™ì½©":12,"ì¸ë„":17,"ì˜êµ­":18,"ë…ì¼":19,"í”„ë‘ìŠ¤":13,"ë©•ì‹œì½”":13,"ìºë‚˜ë‹¤":20,"í•œêµ­":4, "í˜¸ì£¼":21,"ë¸Œë¼ì§ˆ":11,"ìŠ¤í˜ì¸":11}),
        ("2025-10-13", {"ë¯¸êµ­":16,"ì¼ë³¸":22,"í™ì½©":11,"ì¸ë„":14,"ì˜êµ­":None,"ë…ì¼":23,"í”„ë‘ìŠ¤":16,"ë©•ì‹œì½”":7, "ìºë‚˜ë‹¤":18,"í•œêµ­":3, "í˜¸ì£¼":17,"ë¸Œë¼ì§ˆ":12,"ìŠ¤í˜ì¸":11}),
        ("2025-10-20", {"ë¯¸êµ­":21,"ì¼ë³¸":None,"í™ì½©":22,"ì¸ë„":20,"ì˜êµ­":None,"ë…ì¼":None,"í”„ë‘ìŠ¤":23,"ë©•ì‹œì½”":14,"ìºë‚˜ë‹¤":24,"í•œêµ­":4, "í˜¸ì£¼":23,"ë¸Œë¼ì§ˆ":18,"ìŠ¤í˜ì¸":None}),
        ("2025-10-27", {"ë¯¸êµ­":11,"ì¼ë³¸":8, "í™ì½©":23,"ì¸ë„":None,"ì˜êµ­":None,"ë…ì¼":None,"í”„ë‘ìŠ¤":23,"ë©•ì‹œì½”":13,"ìºë‚˜ë‹¤":15,"í•œêµ­":8, "í˜¸ì£¼":None,"ë¸Œë¼ì§ˆ":12,"ìŠ¤í˜ì¸":16}),
        ("2025-11-03", {"ë¯¸êµ­":8, "ì¼ë³¸":23,"í™ì½©":None,"ì¸ë„":20,"ì˜êµ­":None,"ë…ì¼":None,"í”„ë‘ìŠ¤":22,"ë©•ì‹œì½”":14,"ìºë‚˜ë‹¤":12,"í•œêµ­":7, "í˜¸ì£¼":16,"ë¸Œë¼ì§ˆ":8, "ìŠ¤í˜ì¸":13}),
        ("2025-11-10", {"ë¯¸êµ­":8, "ì¼ë³¸":24,"í™ì½©":23,"ì¸ë„":1, "ì˜êµ­":None,"ë…ì¼":None,"í”„ë‘ìŠ¤":22,"ë©•ì‹œì½”":14,"ìºë‚˜ë‹¤":12,"í•œêµ­":7, "í˜¸ì£¼":16,"ë¸Œë¼ì§ˆ":7, "ìŠ¤í˜ì¸":15}),
        ("2025-11-17", {"ë¯¸êµ­":23,"ì¼ë³¸":None,"í™ì½©":17,"ì¸ë„":11,"ì˜êµ­":None,"ë…ì¼":None,"í”„ë‘ìŠ¤":24,"ë©•ì‹œì½”":16,"ìºë‚˜ë‹¤":None,"í•œêµ­":14,"í˜¸ì£¼":None,"ë¸Œë¼ì§ˆ":15,"ìŠ¤í˜ì¸":17}),
        ("2025-11-24", {"ë¯¸êµ­":None,"ì¼ë³¸":None,"í™ì½©":24,"ì¸ë„":13,"ì˜êµ­":19,"ë…ì¼":None,"í”„ë‘ìŠ¤":22,"ë©•ì‹œì½”":10,"ìºë‚˜ë‹¤":22,"í•œêµ­":9, "í˜¸ì£¼":19,"ë¸Œë¼ì§ˆ":13,"ìŠ¤í˜ì¸":None}),
        ("2025-12-01", {"ë¯¸êµ­":20,"ì¼ë³¸":None,"í™ì½©":20,"ì¸ë„":14,"ì˜êµ­":20,"ë…ì¼":16,"í”„ë‘ìŠ¤":18,"ë©•ì‹œì½”":17,"ìºë‚˜ë‹¤":18,"í•œêµ­":12,"í˜¸ì£¼":15,"ë¸Œë¼ì§ˆ":12,"ìŠ¤í˜ì¸":22}),
        ("2025-12-08", {"ë¯¸êµ­":17,"ì¼ë³¸":None,"í™ì½©":23,"ì¸ë„":14,"ì˜êµ­":13,"ë…ì¼":21,"í”„ë‘ìŠ¤":11,"ë©•ì‹œì½”":12,"ìºë‚˜ë‹¤":22,"í•œêµ­":9, "í˜¸ì£¼":11,"ë¸Œë¼ì§ˆ":10,"ìŠ¤í˜ì¸":21}),
        ("2025-12-15", {"ë¯¸êµ­":9, "ì¼ë³¸":21,"í™ì½©":12,"ì¸ë„":8, "ì˜êµ­":10,"ë…ì¼":12,"í”„ë‘ìŠ¤":9, "ë©•ì‹œì½”":9, "ìºë‚˜ë‹¤":7, "í•œêµ­":9, "í˜¸ì£¼":6, "ë¸Œë¼ì§ˆ":7, "ìŠ¤í˜ì¸":12}),
        ("2025-12-22", {"ë¯¸êµ­":22,"ì¼ë³¸":None,"í™ì½©":None,"ì¸ë„":23,"ì˜êµ­":None,"ë…ì¼":18,"í”„ë‘ìŠ¤":23,"ë©•ì‹œì½”":15,"ìºë‚˜ë‹¤":19,"í•œêµ­":18,"í˜¸ì£¼":None,"ë¸Œë¼ì§ˆ":23,"ìŠ¤í˜ì¸":19}),
        ("2025-12-29", {"ë¯¸êµ­":20,"ì¼ë³¸":21,"í™ì½©":23,"ì¸ë„":17,"ì˜êµ­":None,"ë…ì¼":20,"í”„ë‘ìŠ¤":10,"ë©•ì‹œì½”":19,"ìºë‚˜ë‹¤":21,"í•œêµ­":11,"í˜¸ì£¼":10,"ë¸Œë¼ì§ˆ":11,"ìŠ¤í˜ì¸":23}),
        ("2026-01-05", {"ë¯¸êµ­":15,"ì¼ë³¸":None,"í™ì½©":15,"ì¸ë„":9, "ì˜êµ­":17,"ë…ì¼":14,"í”„ë‘ìŠ¤":11,"ë©•ì‹œì½”":14,"ìºë‚˜ë‹¤":15,"í•œêµ­":10,"í˜¸ì£¼":20,"ë¸Œë¼ì§ˆ":11,"ìŠ¤í˜ì¸":13}),
    ]

    CUTOFF = datetime.strptime("2026-01-11", "%Y-%m-%d")

    from datetime import timedelta
    result = []
    for week_start_str, country_ranks in weekly_raw:
        week_start = datetime.strptime(week_start_str, "%Y-%m-%d")

        wa_num, wa_den = 0.0, 0.0
        for c, v in country_ranks.items():
            if v is not None:
                m = get_multiplier(c)
                wa_num += v * m; wa_den += m
        avg_rank = round(wa_num / wa_den, 1) if wa_den > 0 else 15.0

        for day_offset in range(7):
            day = week_start + timedelta(days=day_offset)
            if day >= CUTOFF:
                break
            result.append({
                "date": day.strftime("%Y-%m-%d"),
                "average_rank": avg_rank,
                "country_ranks": country_ranks
            })

    seen = {}
    for item in result:
        seen[item['date']] = item
    result = sorted(seen.values(), key=lambda x: x['date'])

    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(result, f, ensure_ascii=False, indent=2)

    print(f'âœ“ historical_ranking_data.json ìƒì„±: {len(result)}ì¼ì¹˜ ë°ì´í„° â†’ {output_path}')
    return result


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    setup_korean_font()
    
    data_file = 'rank_history.json'
    discord_webhook = os.environ.get('DISCORD_WEBHOOK', '')
    
    if not os.path.exists(data_file):
        print(f'âŒ Error: {data_file} not found')
        return
    
    print('ğŸ“Š Loading data...')
    data = load_data(data_file)
    
    print('ğŸ“ˆ Parsing data...')
    country_data, dates = parse_data(data)
    
    print(f'ğŸ“… Date range: {dates[0].date()} to {dates[-1].date()}')
    print(f'ğŸŒ Countries: {len(country_data)}')
    print()
    
    print('ğŸ“‹ Creating ranking text...')
    table_texts = create_ranking_table(data)
    print()
    
    historical_file = 'historical_ranking_data.json'
    if not os.path.exists(historical_file):
        print('ğŸ“… historical_ranking_data.json not found â†’ building from weekly data...')
        build_historical_data_from_weekly(historical_file)
        print()

    print('ğŸ’° Estimating daily sales...')
    sales_table_path, sales_chart_path, daily_sales = estimate_daily_sales(data)
    print()
    
    latest_rankings = get_latest_rankings(data)
    
    print('ğŸ¨ Generating individual country plots...')
    plot_country_rankings(country_data)
    print()
    
    print('ğŸ¨ Generating combined Standard plot...')
    plot_all_countries_standard(country_data)
    print()
    
    print('ğŸ¨ Generating combined Deluxe plot...')
    plot_all_countries_deluxe(country_data)
    print()
    
    print('ğŸ¨ Generating daily average plots...')
    plot_daily_averages(country_data)
    print()
    
    print('âœ… All plots generated successfully!')
    print(f'ğŸ“ Output directory: output/')
    print()
    
    if discord_webhook:
        print('ğŸ“¤ Sending latest rankings to Discord...')
        send_latest_rankings_to_discord(discord_webhook, latest_rankings, table_texts, daily_sales)
        print()
        
        print('ğŸ“¤ Sending graph notification to Discord...')
        send_discord_notification(discord_webhook, country_data, dates)
    else:
        print('â„¹ï¸  Set DISCORD_WEBHOOK environment variable to enable notifications')

if __name__ == '__main__':
    main()
